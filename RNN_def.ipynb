{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T01:07:18.197786Z",
     "start_time": "2025-05-15T00:22:58.216983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# --- Cargar dataset ---\n",
    "df = pd.read_csv(\"dataset_final.csv\")\n",
    "\n",
    "# --- Mapear userId y movieId a Ã­ndices ---\n",
    "unique_users = df['userId'].unique()\n",
    "unique_movies = df['movieId'].unique()\n",
    "\n",
    "user_id_map = {uid: idx for idx, uid in enumerate(unique_users)}\n",
    "movie_id_map = {mid: idx for idx, mid in enumerate(unique_movies)}\n",
    "\n",
    "df['userId'] = df['userId'].map(user_id_map)\n",
    "df['movieId'] = df['movieId'].map(movie_id_map)\n",
    "\n",
    "# --- Guardar mapeos para luego predecir ---\n",
    "joblib.dump(user_id_map, 'user_id_map.pkl')\n",
    "joblib.dump(movie_id_map, 'movie_id_map.pkl')\n",
    "\n",
    "# --- Separar features y target ---\n",
    "feature_cols = [\n",
    "    'temporal_1', 'temporal_2', 'temporal_3',\n",
    "    'rating_previous', 'is_weekend', 'season_encoded', 'is_holiday',\n",
    "    'year', 'month', 'weekday',\n",
    "    'consumo_semanal_usuario', 'antiguedad_rating', 'diferencia_rating_anterior'\n",
    "]\n",
    "\n",
    "X_user = df['userId'].values\n",
    "X_movie = df['movieId'].values\n",
    "X_others = df[feature_cols].values.reshape((df.shape[0], 1, len(feature_cols)))\n",
    "y = df['rating'].values\n",
    "\n",
    "# --- Separar train/test ---\n",
    "X_train_user, X_test_user, X_train_movie, X_test_movie, X_train_others, X_test_others, y_train, y_test = train_test_split(\n",
    "    X_user, X_movie, X_others, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- Definir modelo ---\n",
    "n_users = len(user_id_map)\n",
    "n_movies = len(movie_id_map)\n",
    "\n",
    "user_input = Input(shape=(1,), name='user_input')\n",
    "movie_input = Input(shape=(1,), name='movie_input')\n",
    "other_input = Input(shape=(1, len(feature_cols)), name='other_features_input')\n",
    "\n",
    "user_emb = Embedding(input_dim=n_users+1, output_dim=16, name='user_embedding')(user_input)\n",
    "movie_emb = Embedding(input_dim=n_movies+1, output_dim=16, name='movie_embedding')(movie_input)\n",
    "\n",
    "user_vec = Flatten()(user_emb)\n",
    "movie_vec = Flatten()(movie_emb)\n",
    "\n",
    "concat_emb = Concatenate()([user_vec, movie_vec])\n",
    "concat_emb = tf.expand_dims(concat_emb, axis=1)  # Lo mismo que reshape para concatenar\n",
    "\n",
    "x = Concatenate()([concat_emb, other_input])\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output = Dense(1, activation='linear')(x)\n",
    "\n",
    "model = Model(inputs=[user_input, movie_input, other_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# --- Entrenar ---\n",
    "model.fit(\n",
    "    [X_train_user, X_train_movie, X_train_others],\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_data=([X_test_user, X_test_movie, X_test_others], y_test)\n",
    ")"
   ],
   "id": "654b78af87112359",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 19:22:59.956327: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-14 19:22:59.956419: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-14 19:23:00.061873: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-14 19:23:00.280632: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-14 19:23:01.707544: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-05-14 19:23:12.712067: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-14 19:23:13.537788: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-14 19:23:13.540015: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-14 19:23:13.543377: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-14 19:23:13.545967: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-14 19:23:13.548385: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-14 19:23:13.698435: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-14 19:23:13.700802: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-14 19:23:13.703007: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-14 19:23:13.705136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5915 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 19:23:15.948580: I external/local_xla/xla/service/service.cc:168] XLA service 0x770529e72780 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-05-14 19:23:15.948616: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050, Compute Capability 8.6\n",
      "2025-05-14 19:23:15.972861: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-05-14 19:23:16.034721: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747268596.147892    7203 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66668/66668 [==============================] - 275s 4ms/step - loss: 1.3539 - val_loss: 2.6944e-04\n",
      "Epoch 2/10\n",
      "66668/66668 [==============================] - 263s 4ms/step - loss: 0.0041 - val_loss: 1.2896e-05\n",
      "Epoch 3/10\n",
      "66668/66668 [==============================] - 264s 4ms/step - loss: 9.1360e-04 - val_loss: 1.7655e-04\n",
      "Epoch 4/10\n",
      "66668/66668 [==============================] - 263s 4ms/step - loss: 5.7132e-04 - val_loss: 1.8155e-04\n",
      "Epoch 5/10\n",
      "66668/66668 [==============================] - 262s 4ms/step - loss: 4.0128e-04 - val_loss: 5.4400e-04\n",
      "Epoch 6/10\n",
      "66668/66668 [==============================] - 263s 4ms/step - loss: 3.1831e-04 - val_loss: 9.2384e-05\n",
      "Epoch 7/10\n",
      "66668/66668 [==============================] - 263s 4ms/step - loss: 2.6621e-04 - val_loss: 7.6751e-05\n",
      "Epoch 8/10\n",
      "66668/66668 [==============================] - 263s 4ms/step - loss: 2.3517e-04 - val_loss: 2.0134e-05\n",
      "Epoch 9/10\n",
      "66668/66668 [==============================] - 264s 4ms/step - loss: 2.1204e-04 - val_loss: 2.9330e-04\n",
      "Epoch 10/10\n",
      "66668/66668 [==============================] - 263s 4ms/step - loss: 1.9600e-04 - val_loss: 1.1267e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7706cf5887f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T01:10:24.619217Z",
     "start_time": "2025-05-15T01:08:15.082102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# ð¹ 12. EvaluaciÃ³n del modelo en test (loss es MSE, rmse lo calculamos manualmente)\n",
    "loss = model.evaluate([X_test_user, X_test_movie, X_test_others], y_test, verbose=1)\n",
    "print(f\"\\nâ Loss (MSE) final de la RNN: {loss:.4f}\")\n",
    "\n",
    "# Predicciones continuas\n",
    "y_pred_continuous = model.predict([X_test_user, X_test_movie, X_test_others]).flatten()\n",
    "\n",
    "# Calcular RMSE manual\n",
    "rmse_manual = np.sqrt(mean_squared_error(y_test, y_pred_continuous))\n",
    "print(f\"â RMSE (cÃ¡lculo manual): {rmse_manual:.4f}\")\n",
    "\n",
    "# Redondear para clasificaciÃ³n aproximada\n",
    "y_pred_class = np.round(y_pred_continuous)\n",
    "y_true_class = np.round(y_test)\n",
    "\n",
    "# MÃ©tricas de clasificaciÃ³n (solo si quieres evaluar como clasificaciÃ³n aproximada)\n",
    "accuracy = accuracy_score(y_true_class, y_pred_class)\n",
    "precision = precision_score(y_true_class, y_pred_class, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true_class, y_pred_class, average='weighted')\n",
    "f1 = f1_score(y_true_class, y_pred_class, average='weighted')\n",
    "\n",
    "print(f\"â Accuracy (clasificaciÃ³n redondeada): {accuracy:.4f}\")\n",
    "print(f\"â Precision (clasificaciÃ³n redondeada): {precision:.4f}\")\n",
    "print(f\"â Recall (clasificaciÃ³n redondeada): {recall:.4f}\")\n",
    "print(f\"â F1-Score (clasificaciÃ³n redondeada): {f1:.4f}\")\n",
    "\n",
    "# ð¹ 14. Guardar modelo\n",
    "model.save(\"edu.h5\")\n",
    "print(\"â Modelo y mapas guardados exitosamente.\")\n"
   ],
   "id": "8316a8a8ed0c62a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33334/33334 [==============================] - 81s 2ms/step - loss: 1.1267e-05\n",
      "\n",
      "â Loss (MSE) final de la RNN: 0.0000\n",
      "33334/33334 [==============================] - 33s 990us/step\n",
      "â RMSE (cÃ¡lculo manual): 0.0034\n",
      "â Accuracy (clasificaciÃ³n redondeada): 0.8375\n",
      "â Precision (clasificaciÃ³n redondeada): 0.8916\n",
      "â Recall (clasificaciÃ³n redondeada): 0.8375\n",
      "â F1-Score (clasificaciÃ³n redondeada): 0.8342\n",
      "â Modelo y mapas guardados exitosamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduardo/PycharmProjects/Calculo_Entropia/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T01:15:15.477007Z",
     "start_time": "2025-05-15T01:15:15.444436Z"
    }
   },
   "cell_type": "code",
   "source": "print(model.summary())",
   "id": "ee5b9f8435eb28f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " movie_input (InputLayer)    [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)  (None, 1, 16)                3206160   ['user_input[0][0]']          \n",
      "                                                                                                  \n",
      " movie_embedding (Embedding  (None, 1, 16)                814080    ['movie_input[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 16)                   0         ['user_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 16)                   0         ['movie_embedding[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 32)                   0         ['flatten[0][0]',             \n",
      "                                                                     'flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda  (None, 1, 32)                0         ['concatenate[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " other_features_input (Inpu  [(None, 1, 13)]              0         []                            \n",
      " tLayer)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 1, 45)                0         ['tf.expand_dims[0][0]',      \n",
      " )                                                                   'other_features_input[0][0]']\n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 45)                   0         ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  5888      ['flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 64)                   8256      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    65        ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4034449 (15.39 MB)\n",
      "Trainable params: 4034449 (15.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T10:55:19.849225Z",
     "start_time": "2025-05-09T10:54:25.434801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ð Predecir en el test set\n",
    "y_pred_continuous = model.predict([X_test_user, X_test_movie, X_test_others]).flatten()\n",
    "\n",
    "# ð¹ Seleccionamos 5 ejemplos aleatorios para mostrar\n",
    "import random\n",
    "\n",
    "# Escogemos 5 Ã­ndices aleatorios\n",
    "random_indices = random.sample(range(len(y_test)), 5)\n",
    "\n",
    "print(\"\\n Ejemplos de predicciÃ³n:\\n\")\n",
    "for idx in random_indices:\n",
    "    print(f\"Usuario ID: {X_test_user[idx]}\")\n",
    "    print(f\"PelÃ­cula ID: {X_test_movie[idx]}\")\n",
    "    print(f\"Rating real: {y_test.iloc[idx]:.1f}\")\n",
    "    print(f\"Rating predicho: {y_pred_continuous[idx]:.2f}\")\n",
    "    print(\"-\" * 40)\n"
   ],
   "id": "fcec5c38fc3f7af8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33334/33334 [==============================] - 47s 1ms/step\n",
      "\n",
      " Ejemplos de predicciÃ³n:\n",
      "\n",
      "Usuario ID: 57248\n",
      "PelÃ­cula ID: 1704\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsuario ID: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mX_test_user[idx]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPelÃ­cula ID: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mX_test_movie[idx]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRating real: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43my_test\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m[idx]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.1f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRating predicho: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my_pred_continuous[idx]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m40\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T10:59:04.680706Z",
     "start_time": "2025-05-09T10:59:04.675127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ð AnÃ¡lisis estadÃ­stico de las predicciones\n",
    "import numpy as np\n",
    "\n",
    "min_rating = np.min(y_pred_continuous)\n",
    "max_rating = np.max(y_pred_continuous)\n",
    "mean_rating = np.mean(y_pred_continuous)\n",
    "std_rating = np.std(y_pred_continuous)\n",
    "\n",
    "print(\"\\n AnÃ¡lisis de las predicciones:\\n\")\n",
    "print(f\" MÃ­nimo rating predicho: {min_rating:.2f}\")\n",
    "print(f\" MÃ¡ximo rating predicho: {max_rating:.2f}\")\n",
    "print(f\" Promedio de ratings predichos: {mean_rating:.2f}\")\n",
    "print(f\" DesviaciÃ³n estÃ¡ndar de ratings predichos: {std_rating:.2f}\")\n"
   ],
   "id": "6313b82e2f7a53e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " AnÃ¡lisis de las predicciones:\n",
      "\n",
      " MÃ­nimo rating predicho: 0.87\n",
      " MÃ¡ximo rating predicho: 4.99\n",
      " Promedio de ratings predichos: 3.56\n",
      " DesviaciÃ³n estÃ¡ndar de ratings predichos: 1.05\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T03:14:10.272339Z",
     "start_time": "2025-05-15T03:10:12.448078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import holidays\n",
    "\n",
    "# 1. Cargar dataset histÃ³rico (con ratings)\n",
    "df_train = pd.read_csv(\"dataset_final.csv\", sep=',')  # ajusta sep segÃºn tu archivo\n",
    "df_train = df_train.sort_values(['userId', 'timestamp'])\n",
    "\n",
    "# 2. Cargar dataset para predecir (sin ratings)\n",
    "df_pred = pd.read_csv(\"test.csv\", sep=';')  # ajusta sep\n",
    "\n",
    "# 3. Combinar histÃ³rico y predicciÃ³n para calcular variables histÃ³ricas\n",
    "df_train_sub = df_train[['userId', 'movieId', 'timestamp', 'rating']]\n",
    "df_pred_sub = df_pred[['userId', 'movieId', 'timestamp']]\n",
    "\n",
    "df_combined = pd.concat([df_train_sub, df_pred_sub], ignore_index=True, sort=False)\n",
    "df_combined = df_combined.sort_values(['userId', 'timestamp'])\n",
    "\n",
    "# 4. Calcular rating_previous y diferencia_rating_anterior\n",
    "df_combined['rating_previous'] = df_combined.groupby('userId')['rating'].shift().fillna(0)\n",
    "df_combined['diferencia_rating_anterior'] = df_combined['rating'] - df_combined['rating_previous']\n",
    "\n",
    "# 5. Extraer solo filas correspondientes a datos de predicciÃ³n\n",
    "df_pred_updated = df_combined.loc[df_combined.index >= len(df_train)].copy()\n",
    "\n",
    "# 6. Rellenar NaN si es necesario\n",
    "df_pred_updated['rating_previous'] = df_pred_updated['rating_previous'].fillna(0)\n",
    "df_pred_updated['diferencia_rating_anterior'] = df_pred_updated['diferencia_rating_anterior'].fillna(0)\n",
    "\n",
    "# 7. AÃ±adir esas columnas a df_pred original (asegÃºrate que los Ã­ndices coincidan)\n",
    "df_pred['rating_previous'] = df_pred_updated['rating_previous'].values\n",
    "df_pred['diferencia_rating_anterior'] = df_pred_updated['diferencia_rating_anterior'].values\n",
    "\n",
    "# 8. Crear variables temporales y demÃ¡s caracterÃ­sticas\n",
    "df_pred['date'] = pd.to_datetime(df_pred['timestamp'], unit='s')\n",
    "df_pred['year'] = df_pred['date'].dt.year\n",
    "df_pred['month'] = df_pred['date'].dt.month\n",
    "df_pred['weekday'] = df_pred['date'].dt.weekday\n",
    "\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]: return 0\n",
    "    elif month in [3, 4, 5]: return 1\n",
    "    elif month in [6, 7, 8]: return 2\n",
    "    else: return 3\n",
    "\n",
    "df_pred['season_encoded'] = df_pred['month'].apply(get_season)\n",
    "df_pred['is_weekend'] = df_pred['weekday'].isin([5, 6]).astype(int)\n",
    "\n",
    "ecu_holidays = holidays.Ecuador(years=range(df_pred['year'].min(), df_pred['year'].max() + 1))\n",
    "df_pred['is_holiday'] = df_pred['date'].isin(ecu_holidays).astype(int)\n",
    "\n",
    "df_pred['week_of_year'] = df_pred['date'].dt.isocalendar().week.astype(int)\n",
    "df_pred['consumo_semanal_usuario'] = 0\n",
    "df_pred['antiguedad_rating'] = 2025 - df_pred['year']\n",
    "\n",
    "# 9. Cargar scaler, UMAP y diccionarios\n",
    "scaler = joblib.load('scaler_temporal.pkl')\n",
    "umap_model = joblib.load('umap_model.pkl')\n",
    "user_id_map = joblib.load('user_id_map.pkl')\n",
    "movie_id_map = joblib.load('movie_id_map.pkl')\n",
    "\n",
    "# 10. Mapear userId y movieId\n",
    "df_pred['userId'] = df_pred['userId'].map(user_id_map).fillna(-1).astype(int)\n",
    "df_pred['movieId'] = df_pred['movieId'].map(movie_id_map).fillna(-1).astype(int)\n",
    "\n",
    "# 11. Escalar y aplicar UMAP\n",
    "temporal_features = ['year', 'month', 'weekday', 'season_encoded', 'is_weekend', 'is_holiday', 'rating_previous']\n",
    "X_temp = scaler.transform(df_pred[temporal_features])\n",
    "X_umap = umap_model.transform(X_temp)\n",
    "df_pred[['temporal_1', 'temporal_2', 'temporal_3']] = X_umap\n",
    "\n",
    "# 12. Preparar inputs para modelo\n",
    "feature_cols = [\n",
    "    'temporal_1', 'temporal_2', 'temporal_3',\n",
    "    'rating_previous', 'is_weekend', 'season_encoded', 'is_holiday',\n",
    "    'year', 'month', 'weekday',\n",
    "    'consumo_semanal_usuario', 'antiguedad_rating', 'diferencia_rating_anterior'\n",
    "]\n",
    "\n",
    "X_pred_user = df_pred['userId'].values\n",
    "X_pred_movie = df_pred['movieId'].values\n",
    "X_pred_others = df_pred[feature_cols].values.reshape((df_pred.shape[0], 1, len(feature_cols)))\n",
    "\n",
    "# 13. Cargar modelo y predecir\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"edu.h5\")\n",
    "\n",
    "predicted_ratings = model.predict([X_pred_user, X_pred_movie, X_pred_others])\n",
    "# Redondear a mÃºltiplos de 0.5\n",
    "df_pred['predicted_rating'] = np.round(predicted_ratings.flatten() * 2) / 2\n",
    "\n",
    "df_predicted_only = df_pred[['predicted_rating']]\n",
    "\n",
    "# Guardar solo esa columna en CSV\n",
    "df_predicted_only.to_csv(\"predicciones_arce_cordova.csv\", index=False)\n"
   ],
   "id": "ab85e09b5900ec5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7121/1789184635.py:51: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df_pred['is_holiday'] = df_pred['date'].isin(ecu_holidays).astype(int)\n",
      "/home/eduardo/PycharmProjects/Calculo_Entropia/.venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32768/32768 [==============================] - 32s 979us/step\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T01:59:08.500366Z",
     "start_time": "2025-05-15T01:58:14.931072Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32768/32768 [==============================] - 34s 1ms/step\n"
     ]
    }
   ],
   "execution_count": 17,
   "source": [
    "predictions = model.predict([X_pred_user, X_pred_movie, X_pred_others])\n",
    "\n",
    "df_pred['predicted_rating'] = predictions.flatten()  # asegÃºrate que es 1D\n",
    "\n",
    "df_pred.to_csv('edu_pred2.csv', index=False)\n"
   ],
   "id": "19310e3da9b18daf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T02:44:41.025570Z",
     "start_time": "2025-05-15T02:44:35.859858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train = pd.read_csv(\"dataset_final.csv\", sep=';')\n",
    "print(df_train.columns)\n"
   ],
   "id": "114f7dbc77164574",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['userId,movieId,temporal_1,temporal_2,temporal_3,rating,timestamp,rating_previous,is_weekend,season_encoded,is_holiday,year,month,weekday,consumo_semanal_usuario,antiguedad_rating,diferencia_rating_anterior'], dtype='object')\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T02:13:14.675694Z",
     "start_time": "2025-05-15T02:13:14.564862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ejemplo de 10 registros para predecir ratings\n",
    "# user_id y movie_id son enteros indexados (ejemplo arbitrario)\n",
    "user_ids = np.array([0, 0, 1, 2, 1, 3, 2, 4, 3, 0])\n",
    "movie_ids = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "# 13 caracterÃ­sticas para cada registro (arbitrarias y con algo de variaciÃ³n)\n",
    "other_features = np.array([\n",
    "    [5.1, 10.4, 6.2, 0, 1, 3, 0, 1999, 11, 6, 3, 26, 5],\n",
    "    [5.0, 10.5, 6.0, 5, 1, 3, 0, 1999, 11, 6, 3, 26, 0],\n",
    "    [-10.2, 5.3, 1.2, 0, 1, 3, 0, 1999, 11, 6, 3, 26, -4],\n",
    "    [15.5, 17.6, -1.2, 1, 0, 3, 0, 1999, 11, 0, 3, 26, 1],\n",
    "    [-5.0, 2.6, 3.8, 2, 0, 3, 0, 1999, 11, 0, 3, 26, 3],\n",
    "    [15.0, 7.8, -8.8, 5, 0, 3, 0, 1999, 11, 0, 3, 26, 0],\n",
    "    [1.0, 1.0, 1.0, 3, 0, 2, 1, 2000, 1, 1, 2, 10, -1],\n",
    "    [3.0, 3.0, 3.0, 0, 1, 1, 0, 2001, 6, 3, 0, 12, 4],\n",
    "    [7.5, 8.0, 7.0, 4, 1, 2, 0, 2002, 12, 5, 1, 14, 2],\n",
    "    [0.0, 0.0, 0.0, 0, 0, 0, 0, 1998, 5, 4, 2, 20, 0],\n",
    "])\n",
    "\n",
    "# Reshape para que tenga (batch_size, 1, 13)\n",
    "other_features = other_features.reshape((10, 1, 13))\n",
    "\n",
    "# Suponiendo que tienes el modelo cargado como 'model'\n",
    "predictions = model.predict([user_ids, movie_ids, other_features])\n",
    "\n",
    "for i, pred in enumerate(predictions.flatten()):\n",
    "    print(f\"Ejemplo {i+1}: PredicciÃ³n rating = {pred:.3f}\")\n"
   ],
   "id": "b647c7362df19ec9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "Ejemplo 1: PredicciÃ³n rating = 5.003\n",
      "Ejemplo 2: PredicciÃ³n rating = 5.002\n",
      "Ejemplo 3: PredicciÃ³n rating = -0.074\n",
      "Ejemplo 4: PredicciÃ³n rating = 2.001\n",
      "Ejemplo 5: PredicciÃ³n rating = 5.002\n",
      "Ejemplo 6: PredicciÃ³n rating = 5.002\n",
      "Ejemplo 7: PredicciÃ³n rating = 2.015\n",
      "Ejemplo 8: PredicciÃ³n rating = 4.004\n",
      "Ejemplo 9: PredicciÃ³n rating = 5.255\n",
      "Ejemplo 10: PredicciÃ³n rating = 0.263\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
